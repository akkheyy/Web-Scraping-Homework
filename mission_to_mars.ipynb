{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from splinter import Browser\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nasa Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_url = \"https://mars.nasa.gov/news/\"\n",
    "text = requests.get(news_url).text\n",
    "news_file_name = \"news-html-requests.txt\"\n",
    "news_file = \"news-selenium-.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(news_file_name, \"w+\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(40)\n",
    "driver.get(news_url)\n",
    "news_html = driver.page_source\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(news_file, \"w+\") as f:\n",
    "    f.write(news_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(news_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_article = soup.find(\"div\", class_=\"list_text\")\n",
    "news_title = news_article.find(\"div\", class_=\"content_title\").text\n",
    "news_p = news_article.find(\"div\", class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "image_text = requests.get(image_url).text\n",
    "soup = BeautifulSoup(image_text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = soup.find(\"div\", class_=\"carousel_container\")\n",
    "for a in image.find_all(\"a\", class_=\"button fancybox\"):\n",
    "    featured_image_url = urllib.parse.urljoin(\n",
    "        \"https://www.jpl.nasa.gov\", a[\"data-fancybox-href\"]\n",
    "    )\n",
    "    print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "weather_file = \"weather-html-requests.txt\"\n",
    "weather_text = requests.get(weather_url).text\n",
    "soup = BeautifulSoup(weather_text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(weather_file, \"w+\") as f:\n",
    "    f.write(weather_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = soup.find(\"div\", class_=\"js-tweet-text-container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = weather.find(\n",
    "    \"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\"\n",
    ").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "facts_text = requests.get(facts_url).text\n",
    "soup = BeautifulSoup(facts_text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_table = soup.find(\"table\")\n",
    "table_rows = facts_table.find_all(\"tr\")\n",
    "l = []\n",
    "for tr in table_rows:\n",
    "    td = tr.find_all(\"td\")\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "facts_df = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_html = facts_df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facts_table = soup.find_all(\"table\")[0] \n",
    "# facts_df = pd.read_html(str(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemispheres_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(hemispheres_url)\n",
    "driver.implicitly_wait(15)\n",
    "hemispheres_html = driver.page_source\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(hemispheres_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = soup.find_all(\"div\", class_=\"item\")\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "for i in items:\n",
    "    title = i.find(\"h3\").text\n",
    "    partial_url = i.find(\"a\", class_=\"itemLink product-item\")[\"href\"]\n",
    "    full_url = urllib.parse.urljoin(\"https://astrogeology.usgs.gov\", partial_url)\n",
    "    browser = Browser(\"firefox\")\n",
    "    browser.visit(full_url)\n",
    "    partial_html = browser.html\n",
    "    soup = BeautifulSoup(partial_html, \"html.parser\")\n",
    "    img_url = (\n",
    "        \"https://astrogeology.usgs.gov\" + soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    )\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": img_url})\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Web-Scraping-Homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
